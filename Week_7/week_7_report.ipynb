{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74bc4af",
   "metadata": {},
   "source": [
    "### Q1.Explain the concept of score matching and describe how it is used in score-based (diffusion) generative models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3e276",
   "metadata": {},
   "source": [
    "### Concept of Score Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830631ed",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "\n",
    "在generative model中，我們想學習資料的分布情況(pdf) \\\n",
    "$p(x) = \\frac{1}{Z(\\theta)} e^{q(x;\\theta)}$ \\\n",
    "但是$Z(\\theta)$非常難求解，因此使用其他方法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436871e1",
   "metadata": {},
   "source": [
    "#### Score function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668835a0",
   "metadata": {},
   "source": [
    "對$p(x)$取log計算，會得到$\\log p(x;\\theta)=q(x;\\theta) -\\log z(\\theta)$ \\\n",
    "令$S(x)=\\nabla_x\\log p(x;\\theta) = \\nabla_x\\log q(x;\\theta)$，$S(x)$被稱為Score function. \\\n",
    "能找出在每個點上，機率密度函數上升最快的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2561d",
   "metadata": {},
   "source": [
    "#### Explict score matching(ESM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1a9e0",
   "metadata": {},
   "source": [
    "想訓練模型$S(x;\\theta) \\approx \\nabla_x \\log p(x)$ \\\n",
    "因此定義$L_{ESM}(\\theta) = \\mathbb{E}_{x\\sim p(x)}\\|S(x; \\theta)-\\nabla_x\\log p(x)\\|^2$ \\\n",
    "但我們不知道真實的梯度($\\nabla_x\\log p(x)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1b673",
   "metadata": {},
   "source": [
    "#### Implicit Score Matching (ISM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df624027",
   "metadata": {},
   "source": [
    "定義$L_{ISM}(\\theta) = \\mathbb{E}_{x\\sim p(x)}\\left[\\|S(x;\\theta)\\|^2 +2\\nabla_x\\cdot S(x;\\theta)\\right].$ \n",
    "\n",
    "使用這個方法就不需計算出$\\nabla_x\\log p(x)$\n",
    "\n",
    "透過計算可以推出： \\\n",
    "$\\mathbb{E}_{x\\sim p(x)}\\left[\\|S(x;\\theta)-\\nabla_x\\log p(x)\\|^2\\right] = \\mathbb{E}_{x\\sim p(x)}\\left[\\left(\\|S(x;\\theta)\\|^2+2\\nabla_x\\cdot S(x;\\theta)\\right)\\right]+\\mathbb{E}_{x\\sim p(x)}\\left[\\|\\nabla_x\\log p(x)\\|^2\\right]$.\n",
    "\n",
    "\n",
    "\n",
    "如果訓練出$S(x;\\theta)=\\nabla_x\\log p(x;\\theta)$時，$L_{ESM}=0$, $L_{ISM} \\leq 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e767f",
   "metadata": {},
   "source": [
    "#### Denoising score matching (DSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e7ebc",
   "metadata": {},
   "source": [
    "在實作中，ISM的計算也沒有那麼方便。\n",
    "因此後來又提出了一個更簡單的方法：\n",
    "\n",
    "先對資料$x$加上noise(更好計算)，希望求出noisy score function $S_\\sigma(x; \\theta)=\\nabla_{x}\\log p_\\sigma(x) \\quad$, $p_\\sigma(x) = \\int_{\\mathbb{R}^d}p(x|x_0)p_0(x_0)\\,dx_0$\n",
    "\n",
    "因此定義$L_{DSM}(\\theta) = \\mathbb{E}_{x_0\\sim p_0(x_0)}\\mathbb{E}_{x|x_0\\sim p(x|x_0)}\\left[\\|S_\\sigma(x;\\theta)-\\nabla_{x}\\log p(x|x_0)\\|^2\\right].$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec9dc3",
   "metadata": {},
   "source": [
    "#### Why Use DSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240e5f9",
   "metadata": {},
   "source": [
    "Adding Gaussian noise with isotropic variance. \\\n",
    "$x = x_0 + \\epsilon_\\sigma, \\quad \\epsilon_\\sigma\\sim \\mathcal{N}(0, \\sigma^2 I),\\\\\n",
    "\\quad = x_0 + \\sigma\\epsilon, \\quad \\epsilon\\sim \\mathcal{N}(0, I),$\n",
    "\n",
    "會得到$\\nabla_x\\log p(x|x_0)= -\\frac{(x-x_0)}{\\sigma^2} $\n",
    "\n",
    "帶入公式得到$L_{DSM}(\\theta) = \\mathbb{E}_{x_0\\sim p_0(x_0)}\\mathbb{E}_{x|x_0\\sim p(x|x_0)}\\left[\\|S_\\sigma(x;\\theta)+\\frac{(x-x_0)}{\\sigma^2}||\\right].$\n",
    "\n",
    "更容易做計算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fbcee",
   "metadata": {},
   "source": [
    "#### Sliced Score Matching（SSM）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121ccb0",
   "metadata": {},
   "source": [
    "在高維度中，$\\nabla_xS(x;\\theta)$是一個巨大的矩陣\n",
    "想計算Trace,必須計算非常多偏導數\n",
    "\n",
    "因此使用了Hutchinson’s trace estimator \\\n",
    "當$\\mathbb{E}[vv^T] = I$，則$\\text{tr}(A) = \\mathbb{E}_[v^TAv].$\n",
    "\n",
    "\n",
    "使用這個方法將ISM改寫得到\n",
    "$L_{SSM}(\\theta) = \\mathbb{E}_{x\\sim p(x)}\\|S(x;\\theta)\\|^2 +\\mathbb{E}_{x\\sim p(x)} \\mathbb{E}_{v\\sim p(v)} \\left[2v^T\\nabla_x (v^TS(x;\\theta))\\right].$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a46979",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f65cd",
   "metadata": {},
   "source": [
    "在 generative models 中，我們想學習資料的機率密度函數 (pdf)，  \n",
    "但直接估計 $p(x;\\theta)$ 很困難。  \n",
    "因此改學它的對數梯度：\n",
    "$$\n",
    "S(x) = \\nabla_x \\log p(x;\\theta)\n",
    "$$\n",
    "稱為 **score function**。  \n",
    "我們希望訓練模型 $S_\\theta(x) \\approx \\nabla_x \\log p(x)$。\n",
    "\n",
    "---\n",
    "#### ESM → ISM\n",
    "\n",
    "最直接的作法是 **Explicit Score Matching (ESM)**，  \n",
    "但它需要知道真實分布的梯度 $\\nabla_x \\log p(x)$，這在實際上不可行。  \n",
    "\n",
    "因此提出 **Implicit Score Matching (ISM)**  \n",
    "它透過數學轉換，將目標改寫為不依賴真實梯度的形式，模型就能只靠資料樣本來訓練。\n",
    "\n",
    "---\n",
    "\n",
    "#### ISM → DSM\n",
    "\n",
    "ISM 訓練不穩定，且模型只在資料點附近有效。  \n",
    "為了讓模型能更穩定地訓練，提出了DSM。\n",
    "\n",
    "DSM 的想法是：  \n",
    "對資料加上高斯噪音 $\\tilde{x} = x + \\epsilon, \\; \\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$，  \n",
    "然後學習 noisy score\n",
    "\n",
    "---\n",
    "\n",
    "#### ISM → SSM\n",
    "為了在高維度中有效估計 $\\nabla_xS_\\theta(x)$，   \n",
    "利用 Hutchinson’s trace estimator 近似：\n",
    "$$\n",
    "\\nabla_x \\cdot S_\\theta(x)\n",
    "= \\mathbb{E}_{v\\sim \\mathcal{N}(0,I)} [v^T \\nabla_x (v^T S_\\theta(x))]\n",
    "$$\n",
    "這樣可以大幅減少計算量。\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac4f61",
   "metadata": {},
   "source": [
    "### Q2 Unanswered questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40414b99",
   "metadata": {},
   "source": [
    "1.在操作DSM時，我們要如何去選擇noise？能夠讓我們方便計算且結果準確。\n",
    "2.我們可以結合DSM與SSM的觀念，將noise與轉換成vector的觀念結合再一起，做出效果可能更好的方法嗎？"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
